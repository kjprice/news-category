{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/uci-news-aggregator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    for ch in string.punctuation:                                                                                                     \n",
    "        s = s.replace(ch, \" \") \n",
    "    s = re.sub(\"[0-9]+\", \"||DIG||\",s)\n",
    "    s = re.sub(' +',' ', s)        \n",
    "    return s\n",
    "\n",
    "data['TEXT'] = [clean_text(s) for s in data['TITLE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>fed official says weak data caused by weather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>fed s charles plosser sees high bar for change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>us open stocks fall after fed official hints a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>fed risks falling behind the curve charles plo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>fed s plosser nasty weather has curbed job growth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE  \\\n",
       "0        b  Fed official says weak data caused by weather,...   \n",
       "1        b  Fed's Charles Plosser sees high bar for change...   \n",
       "2        b  US open: Stocks fall after Fed official hints ...   \n",
       "3        b  Fed risks falling 'behind the curve', Charles ...   \n",
       "4        b  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                TEXT  \n",
       "0  fed official says weak data caused by weather ...  \n",
       "1  fed s charles plosser sees high bar for change...  \n",
       "2  us open stocks fall after fed official hints a...  \n",
       "3  fed risks falling behind the curve charles plo...  \n",
       "4  fed s plosser nasty weather has curbed job growth  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['CATEGORY', 'TITLE', 'TEXT']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First create a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_category = data.groupby('CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count = data_by_category['ID'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_count = category_count.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the highest occuring item and suppose that we predicted all records to be this category\n",
    "max_value = sorted_count.max()\n",
    "total_count = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_value = max_value / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy to beat: 36.094257%\n"
     ]
    }
   ],
   "source": [
    "base_line_accuracy = base_line_value[0]\n",
    "print('Baseline accuracy to beat: {:f}%'.format((base_line_accuracy * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define targets and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "max_features = 10000\n",
    "max_word_vector_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without setting a limit to the number of words, we get 49771 words\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(data['TEXT'])\n",
    "total_words = x.shape[-1]\n",
    "print('Without setting a limit to the number of words, we get {} words'.format(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "x = vectorizer.fit_transform(data['TEXT']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(data['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simple dense neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[-1],)))\n",
    "model.add(layers.Dense(len(category_count), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270348 samples, validate on 67587 samples\n",
      "Epoch 1/3\n",
      "270348/270348 [==============================] - 61s 225us/step - loss: 0.4022 - acc: 0.8905 - val_loss: 0.2062 - val_acc: 0.9295\n",
      "Epoch 2/3\n",
      "270348/270348 [==============================] - 55s 205us/step - loss: 0.1821 - acc: 0.9377 - val_loss: 0.1821 - val_acc: 0.9370\n",
      "Epoch 3/3\n",
      "270348/270348 [==============================] - 56s 208us/step - loss: 0.1641 - acc: 0.9433 - val_loss: 0.1758 - val_acc: 0.9392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1294e7828>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 3,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "max_features = 10000\n",
    "max_word_vector_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(data['TITLE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad = pad_sequences(x, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_pad, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "model = models.Sequential()\n",
    "model.add(Embedding(max_features, max_word_vector_length, input_length=max_len))\n",
    "model.add(layers.LSTM(\n",
    "    32,\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.2,\n",
    "))\n",
    "model.add(layers.Dense(len(category_count), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270348 samples, validate on 67587 samples\n",
      "Epoch 1/3\n",
      "270348/270348 [==============================] - 51s 188us/step - loss: 1.3130 - acc: 0.3610 - val_loss: 1.3130 - val_acc: 0.3621\n",
      "Epoch 2/3\n",
      "270348/270348 [==============================] - 47s 175us/step - loss: 1.3114 - acc: 0.3626 - val_loss: 1.3116 - val_acc: 0.3629\n",
      "Epoch 3/3\n",
      "270348/270348 [==============================] - 47s 174us/step - loss: 1.3107 - acc: 0.3633 - val_loss: 1.3124 - val_acc: 0.3633\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 3,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
